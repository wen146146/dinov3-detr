# !/usr/bin/env python3
"""
æ”¹è¿›ç‰ˆDINOv3+DETRå•å›¾ç‰‡æ£€æµ‹è„šæœ¬
é™ä½è¯†åˆ«ä¸¥æ ¼æ€§ï¼Œæé«˜æ£€æµ‹ç‡
"""

import torch
import torch.nn as nn
from PIL import Image, ImageDraw
import numpy as np
import os

# å¯¼å…¥æ¨¡å‹
from mymodels.dinov3_detr import DINOv3DETR


class  SimpleDetector: #11111111111
    def __init__(self):
        # é€‰æ‹©è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")

        # âœ… ä¿®æ”¹ç±»åˆ«æ•°é‡ï¼ˆæ ¹æ®ä½ çš„è®­ç»ƒè®¾ç½®ï¼‰
        self.num_classes = 10  # ä¿®æ”¹ä¸ºä½ çš„å®é™…ç±»åˆ«æ•°

        # âœ… ä¿®æ”¹æ¨¡å‹æƒé‡è·¯å¾„
        self.model_path = "your_model.pth"  # ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„

        # åŠ è½½æ¨¡å‹
        self.load_model()

    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        print("åŠ è½½æ¨¡å‹...")

        # åˆ›å»ºæ¨¡å‹
        self.model = DINOv3DETR(num_classes=self.num_classes,)

        # åŠ è½½è®­ç»ƒå¥½çš„æ£€æµ‹å¤´æƒé‡
        if os.path.exists(self.model_path):
            print(f"åŠ è½½æƒé‡: {self.model_path}")
            state_dict = torch.load(self.model_path, map_location=self.device)
            self.model.detr_head.load_state_dict(state_dict)
            print("âœ… æ£€æµ‹å¤´æƒé‡åŠ è½½å®Œæˆ")
        else:
            # å°è¯•å¯»æ‰¾å…¶ä»–å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶
            print(f"âš ï¸ è­¦å‘Š: æƒé‡æ–‡ä»¶ä¸å­˜åœ¨ {self.model_path}")
            pth_files = [f for f in os.listdir('.') if f.endswith('.pth')]
            if pth_files:
                print(f"æ‰¾åˆ°å…¶ä»–pthæ–‡ä»¶: {pth_files}")
                # å°è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„pthæ–‡ä»¶
                self.model_path = pth_files[0]
                print(f"å°è¯•åŠ è½½: {self.model_path}")
                state_dict = torch.load(self.model_path, map_location=self.device)
                self.model.detr_head.load_state_dict(state_dict)
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")
                print("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")

        # ç§»åˆ°è®¾å¤‡å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        self.model.to(self.device)
        self.model.eval()
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    def preprocess_image(self, image_path, img_size=224):
        """é¢„å¤„ç†å›¾åƒ"""
        print(f"å¤„ç†å›¾åƒ: {image_path}")

        # æ‰“å¼€å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        orig_width, orig_height = image.size
        print(f"åŸå§‹å°ºå¯¸: {orig_width} x {orig_height}")

        # è°ƒæ•´å¤§å°
        img_resized = image.resize((img_size, img_size), Image.BILINEAR)

        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–
        img_np = np.array(img_resized) / 255.0

        # è½¬æ¢ä¸ºPyTorchå¼ é‡ [H, W, C] -> [C, H, W]
        img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).float()

        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ [C, H, W] -> [1, C, H, W]
        img_tensor = img_tensor.unsqueeze(0)

        return img_tensor, image, (orig_width, orig_height)

    def predict(self, image_tensor, confidence_threshold=0.1):  # âœ… é™ä½é˜ˆå€¼åˆ°0.1
        """æ‰§è¡Œé¢„æµ‹"""
        print("æ‰§è¡Œæ¨ç†...")

        # å°†å›¾åƒç§»åˆ°è®¾å¤‡
        image_tensor = image_tensor.to(self.device)

        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            pred_logits, pred_boxes = self.model(image_tensor)

        # å¤„ç†é¢„æµ‹ç»“æœ
        pred_logits = pred_logits[0]  # [100, num_classes+1]
        pred_boxes = pred_boxes[0]  # [100, 4]

        # è·å–ç±»åˆ«æ¦‚ç‡
        pred_probs = torch.softmax(pred_logits, dim=-1)

        # è·å–æ¯ä¸ªé¢„æµ‹çš„æœ€é«˜ç½®ä¿¡åº¦å’Œç±»åˆ«
        max_probs, max_indices = torch.max(pred_probs, dim=-1)

        # âœ… æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºç½®ä¿¡åº¦åˆ†å¸ƒ
        print(f"\nç½®ä¿¡åº¦ç»Ÿè®¡:")
        print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_probs.max().item():.4f}")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {max_probs.mean().item():.4f}")
        print(f"  ç½®ä¿¡åº¦ > 0.1 çš„æ•°é‡: {(max_probs > 0.1).sum().item()}")
        print(f"  ç½®ä¿¡åº¦ > 0.3 çš„æ•°é‡: {(max_probs > 0.3).sum().item()}")
        print(f"  ç½®ä¿¡åº¦ > 0.5 çš„æ•°é‡: {(max_probs > 0.5).sum().item()}")

        # âœ… æ˜¾ç¤ºå‰10ä¸ªé¢„æµ‹çš„è¯¦ç»†ä¿¡æ¯
        print(f"\nå‰10ä¸ªé¢„æµ‹è¯¦æƒ…:")
        for i in range(min(10, len(max_probs))):
            class_id = max_indices[i].item()
            confidence = max_probs[i].item()
            is_target = class_id < self.num_classes
            status = "âœ“ ç›®æ ‡" if is_target else "âœ— èƒŒæ™¯"
            print(f"  æŸ¥è¯¢{i:2d}: {status} (ç±»{class_id}), ç½®ä¿¡åº¦={confidence:.4f}")

        # âœ… ä¿®æ”¹æ£€æµ‹é€»è¾‘ï¼šæ›´å®½æ¾çš„æ¡ä»¶
        detections = []
        for i in range(len(max_probs)):
            confidence = max_probs[i].item()
            class_id = max_indices[i].item()

            # âœ… ä¿®æ”¹1: é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ (0.5 -> 0.1)
            # âœ… ä¿®æ”¹2: å³ä½¿æ˜¯èƒŒæ™¯ç±»ï¼Œå¦‚æœç½®ä¿¡åº¦å¾ˆé«˜ä¹Ÿè€ƒè™‘
            if confidence >= confidence_threshold:
                bbox = pred_boxes[i].cpu().numpy().tolist()  # [cx, cy, w, h]

                # å¦‚æœæ˜¯ç›®æ ‡ç±»åˆ«
                if class_id < self.num_classes:
                    detections.append({
                        'class_id': class_id,
                        'confidence': confidence,
                        'bbox_cxcywh': bbox,
                        'is_target': True
                    })
                # âœ… ä¿®æ”¹3: å³ä½¿è¢«åˆ†ç±»ä¸ºèƒŒæ™¯ï¼Œä½†ç½®ä¿¡åº¦å¾ˆé«˜ï¼Œä¹Ÿæ˜¾ç¤ºï¼ˆç”¨ä¸åŒé¢œè‰²ï¼‰
                elif confidence > 0.7:  # èƒŒæ™¯ç±»ä½†éå¸¸ç¡®ä¿¡
                    detections.append({
                        'class_id': self.num_classes,  # æ ‡è®°ä¸ºèƒŒæ™¯ç±»
                        'confidence': confidence,
                        'bbox_cxcywh': bbox,
                        'is_target': False
                    })

        print(f"\næ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡ (é˜ˆå€¼={confidence_threshold})")
        return detections

    def draw_boxes(self, image, detections, orig_size, img_size=224):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†"""
        draw = ImageDraw.Draw(image)
        orig_width, orig_height = orig_size

        # é¢œè‰²åˆ—è¡¨ï¼šç›®æ ‡ç”¨å½©è‰²ï¼ŒèƒŒæ™¯ç”¨ç°è‰²
        target_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255),
                         (255, 255, 0), (255, 0, 255)]
        bg_color = (128, 128, 128)  # èƒŒæ™¯æ¡†ç”¨ç°è‰²

        for i, det in enumerate(detections):
            # è·å–è¾¹ç•Œæ¡†åæ ‡
            cx, cy, w, h = det['bbox_cxcywh']

            # è½¬æ¢åˆ°åƒç´ åæ ‡
            cx = cx * img_size
            cy = cy * img_size
            w = w * img_size
            h = h * img_size

            # è½¬æ¢ä¸ºxyxyæ ¼å¼
            x_min = cx - w / 2
            y_min = cy - h / 2
            x_max = cx + w / 2
            y_max = cy + h / 2

            # ç¼©æ”¾åˆ°åŸå§‹å›¾åƒå°ºå¯¸
            scale_x = orig_width / img_size
            scale_y = orig_height / img_size

            x_min = int(x_min * scale_x)
            y_min = int(y_min * scale_y)
            x_max = int(x_max * scale_x)
            y_max = int(y_max * scale_y)

            # ç¡®ä¿åœ¨å›¾åƒèŒƒå›´å†…
            x_min = max(0, x_min)
            y_min = max(0, y_min)
            x_max = min(orig_width, x_max)
            y_max = min(orig_height, y_max)

            # é€‰æ‹©é¢œè‰²ï¼šç›®æ ‡ç”¨å½©è‰²ï¼ŒèƒŒæ™¯ç”¨ç°è‰²
            if det.get('is_target', True):
                color = target_colors[i % len(target_colors)]
                label_prefix = "ç›®æ ‡"
            else:
                color = bg_color
                label_prefix = "èƒŒæ™¯"

            # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆç›®æ ‡ç”¨å®çº¿ï¼ŒèƒŒæ™¯ç”¨è™šçº¿ï¼‰
            if det.get('is_target', True):
                draw.rectangle([x_min, y_min, x_max, y_max],
                               outline=color, width=3)
            else:
                # èƒŒæ™¯ç”¨è™šçº¿ï¼ˆé€šè¿‡ç»˜åˆ¶å¤šä¸ªå°çº¿æ®µå®ç°ï¼‰
                dash_length = 5
                # ä¸Šè¾¹
                for dx in range(x_min, x_max, dash_length * 2):
                    draw.line([dx, y_min, min(dx + dash_length, x_max), y_min],
                              fill=color, width=2)
                # ä¸‹è¾¹
                for dx in range(x_min, x_max, dash_length * 2):
                    draw.line([dx, y_max, min(dx + dash_length, x_max), y_max],
                              fill=color, width=2)
                # å·¦è¾¹
                for dy in range(y_min, y_max, dash_length * 2):
                    draw.line([x_min, dy, x_min, min(dy + dash_length, y_max)],
                              fill=color, width=2)
                # å³è¾¹
                for dy in range(y_min, y_max, dash_length * 2):
                    draw.line([x_max, dy, x_max, min(dy + dash_length, y_max)],
                              fill=color, width=2)

            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{label_prefix}:{det['confidence']:.2f}"
            draw.text((x_min + 5, y_min + 5), label, fill=color)

        return image

    def draw_no_detection(self, image):
        """ç»˜åˆ¶'æœªæ£€æµ‹åˆ°ç›®æ ‡'çš„æç¤º"""
        draw = ImageDraw.Draw(image)
        width, height = image.size

        # ç»˜åˆ¶æç¤ºæ–‡å­—
        text = "âš ï¸ æœªæ£€æµ‹åˆ°é«˜ç½®ä¿¡åº¦ç›®æ ‡"
        # ç®€å•æ–‡æœ¬ï¼ˆå¦‚æœæ²¡æœ‰å­—ä½“ï¼‰
        draw.text((10, 10), text, fill=(255, 0, 0))

        # ç»˜åˆ¶å»ºè®®
        suggestion = "å°è¯•: 1.é™ä½é˜ˆå€¼ 2.æ£€æŸ¥æ¨¡å‹ 3.ä½¿ç”¨è®­ç»ƒé›†å›¾ç‰‡"
        draw.text((10, 30), suggestion, fill=(255, 0, 0))

        return image

    def detect_image(self, image_path, output_path=None, confidence_threshold=0.1):
        """æ£€æµ‹å•å¼ å›¾åƒ"""
        print("=" * 60)
        print(f"å¼€å§‹æ£€æµ‹: {image_path}")
        print("=" * 60)

        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒä¸å­˜åœ¨: {image_path}")
            return None

        # 1. é¢„å¤„ç†
        img_tensor, original_image, orig_size = self.preprocess_image(image_path)

        # 2. é¢„æµ‹ï¼ˆä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ï¼‰
        detections = self.predict(img_tensor, confidence_threshold)

        # 3. ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_path is None:
            base_name = os.path.splitext(image_path)[0]
            output_path = f"{base_name}_detected.jpg"

        # âœ… ä¿®æ”¹ï¼šæ— è®ºå¦‚ä½•éƒ½ä¿å­˜å›¾ç‰‡
        if not detections:
            print("\nâš ï¸ æœªæ£€æµ‹åˆ°é«˜ç½®ä¿¡åº¦ç›®æ ‡")
            print("å°è¯•é™ä½é˜ˆå€¼æˆ–ä½¿ç”¨è®­ç»ƒé›†ä¸­çš„å›¾ç‰‡æµ‹è¯•")

            # å³ä½¿æ²¡æœ‰æ£€æµ‹åˆ°ï¼Œä¹Ÿä¿å­˜åŸå›¾å¹¶æ·»åŠ æç¤º
            result_image = self.draw_no_detection(original_image.copy())
        else:
            # æœ‰æ£€æµ‹ç»“æœï¼šç»˜åˆ¶è¾¹ç•Œæ¡†
            result_image = self.draw_boxes(original_image.copy(), detections, orig_size)

            # æ˜¾ç¤ºæ£€æµ‹ç»“æœç»Ÿè®¡
            print(f"\nğŸ“Š æ£€æµ‹ç»“æœç»Ÿè®¡:")
            target_count = sum(1 for d in detections if d.get('is_target', True))
            bg_count = len(detections) - target_count
            print(f"  ç›®æ ‡æ£€æµ‹æ•°: {target_count}")
            print(f"  èƒŒæ™¯é«˜ç½®ä¿¡æ•°: {bg_count}")

            print(f"\nğŸ” æ£€æµ‹è¯¦æƒ…:")
            for i, det in enumerate(detections):
                if det.get('is_target', True):
                    print(f"  ç›®æ ‡{i + 1}: ç±»åˆ«={det['class_id']}, "
                          f"ç½®ä¿¡åº¦={det['confidence']:.3f}")
                else:
                    print(f"  èƒŒæ™¯{i + 1}: ç½®ä¿¡åº¦={det['confidence']:.3f}")

        # 4. ä¿å­˜ç»“æœ
        result_image.save(output_path)
        print(f"\nâœ… ç»“æœä¿å­˜åˆ°: {output_path}")

        # 5. å°è¯•æ‰“å¼€å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
        try:
            import webbrowser
            webbrowser.open(output_path)
            print(f"ğŸ“¸ æ­£åœ¨æ‰“å¼€å›¾ç‰‡...")
        except:
            pass

        return result_image


# ä¸»å‡½æ•°
def main():
    """æµ‹è¯•æ–¹æ³•"""
    print("=" * 60)
    print("DINOv3+DETR æ”¹è¿›ç‰ˆæ£€æµ‹æµ‹è¯•")
    print("ç‰¹ç‚¹: é™ä½é˜ˆå€¼ã€æ˜¾ç¤ºæ›´å¤šæ£€æµ‹ã€æ— è®ºå¦‚ä½•éƒ½ç»˜å›¾")
    print("=" * 60)

    # åˆ›å»ºæ£€æµ‹å™¨å®ä¾‹
    detector = SimpleDetector()

    # âœ… è®¾ç½®æµ‹è¯•å›¾åƒè·¯å¾„
    test_image_path = "test.jpg"  # ä¿®æ”¹ä¸ºä½ çš„æµ‹è¯•å›¾ç‰‡è·¯å¾„

    # âœ… æ‰§è¡Œæ£€æµ‹ï¼ˆä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ï¼‰
    print(f"\nğŸ”§ æµ‹è¯•é…ç½®:")
    print(f"  å›¾ç‰‡: {test_image_path}")
    print(f"  æ¨¡å‹: {detector.model_path}")
    print(f"  ç±»åˆ«æ•°: {detector.num_classes}")
    print(f"  ç½®ä¿¡åº¦é˜ˆå€¼: 0.1 (è¾ƒä½)")

    # å°è¯•å¤šä¸ªé˜ˆå€¼
    thresholds = [0.1, 0.05, 0.01]

    for threshold in thresholds:
        print(f"\n{'=' * 60}")
        print(f"æµ‹è¯•é˜ˆå€¼: {threshold}")
        print(f"{'=' * 60}")

        # ç”Ÿæˆä¸åŒçš„è¾“å‡ºæ–‡ä»¶å
        base_name = os.path.splitext(test_image_path)[0]
        output_path = f"{base_name}_detected_th{threshold}.jpg"

        detector.detect_image(
            image_path=test_image_path,
            output_path=output_path,
            confidence_threshold=threshold
        )

    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print(f"ç”Ÿæˆäº† {len(thresholds)} ä¸ªä¸åŒé˜ˆå€¼çš„æ£€æµ‹ç»“æœ")
    print("å»ºè®®æ£€æŸ¥ threshold=0.01 çš„ç»“æœ")
    print("=" * 60)


if __name__ == "__main__":
    main()