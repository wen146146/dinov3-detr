#!/usr/bin/env python3
"""
æœ€ç®€åŒ–çš„DINOv3 + DETRæ£€æµ‹å¤´è®­ç»ƒè„šæœ¬
åŒ…å«æ‰€æœ‰å¿…è¦åŠŸèƒ½
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import json
import numpy as np
from tqdm import tqdm
import warnings

import math  # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ 
import matplotlib.pyplot as plt  # å¯é€‰


def adjust_learning_rate(optimizer, epoch, warmup_epochs, base_lr, num_epochs, method='cosine'):
    """
    å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥ï¼ˆé¢„çƒ­ + è¡°å‡ï¼‰

    Args:
        optimizer: ä¼˜åŒ–å™¨
        epoch: å½“å‰epochï¼ˆä»0å¼€å§‹ï¼‰
        warmup_epochs: é¢„çƒ­epochæ•°
        base_lr: åŸºç¡€å­¦ä¹ ç‡
        num_epochs: æ€»epochæ•°
        method: è¡°å‡æ–¹æ³• ('cosine', 'step', 'linear')

    Returns:
        å½“å‰å­¦ä¹ ç‡
    """
    if epoch < warmup_epochs:
        # ğŸ”¥ çº¿æ€§é¢„çƒ­ï¼šä»0.1å€å­¦ä¹ ç‡é€æ¸å¢åŠ åˆ°1å€
        warmup_factor = (epoch + 1) / warmup_epochs
        lr = base_lr * warmup_factor

    else:
        if method == 'cosine':
            # ğŸ”¥ ä½™å¼¦è¡°å‡ï¼ˆæœ€å¹³æ»‘ï¼‰
            progress = (epoch - warmup_epochs) / (num_epochs - warmup_epochs)
            lr = 0.5 * base_lr * (1 + math.cos(math.pi * progress))

        elif method == 'step':
            # é˜¶æ¢¯è¡°å‡
            decay_factor = 0.5 ** ((epoch - warmup_epochs) // 3)
            lr = base_lr * decay_factor

        elif method == 'linear':
            # çº¿æ€§è¡°å‡
            progress = (epoch - warmup_epochs) / (num_epochs - warmup_epochs)
            lr = base_lr * (1 - progress)
        else:
            lr = base_lr

    # è®¾ç½®å­¦ä¹ ç‡
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

    return lr


def plot_training_history(history):
    """
    ç»˜åˆ¶è®­ç»ƒå†å²å›¾è¡¨ï¼ˆå¯é€‰ï¼‰
    """
    if not history['epoch']:
        return

    plt.figure(figsize=(12, 8))

    # 1. æŸå¤±æ›²çº¿
    plt.subplot(2, 2, 1)
    plt.plot(history['epoch'], history['train_loss'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
    plt.plot(history['epoch'], history['val_loss'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
    plt.xlabel('Epoch')
    plt.ylabel('æŸå¤±')
    plt.title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 2. å­¦ä¹ ç‡æ›²çº¿
    plt.subplot(2, 2, 2)
    plt.plot(history['epoch'], history['lr'], 'g-', linewidth=2)
    plt.xlabel('Epoch')
    plt.ylabel('å­¦ä¹ ç‡')
    plt.title('å­¦ä¹ ç‡å˜åŒ–ï¼ˆé¢„çƒ­+è¡°å‡ï¼‰')
    plt.grid(True, alpha=0.3)
    plt.yscale('log')

    # 3. éªŒè¯æŸå¤±æ”¾å¤§
    plt.subplot(2, 2, 3)
    plt.plot(history['epoch'], history['val_loss'], 'r-', linewidth=2, marker='o', markersize=4)
    plt.xlabel('Epoch')
    plt.ylabel('éªŒè¯æŸå¤±')
    plt.title('éªŒè¯æŸå¤±å˜åŒ–ï¼ˆæ—©åœç›‘æ§ï¼‰')
    plt.grid(True, alpha=0.3)

    # æ‰¾åˆ°æœ€å°å€¼ç‚¹
    min_idx = np.argmin(history['val_loss'])
    plt.scatter(history['epoch'][min_idx], history['val_loss'][min_idx],
                color='green', s=100, zorder=5, label=f'æœ€ä½³: {history["val_loss"][min_idx]:.4f}')
    plt.legend()

    # 4. æŸå¤±å·®å€¼ï¼ˆè¿‡æ‹Ÿåˆç¨‹åº¦ï¼‰
    plt.subplot(2, 2, 4)
    diff = [t - v for t, v in zip(history['train_loss'], history['val_loss'])]
    plt.plot(history['epoch'], diff, 'm-', linewidth=2)
    plt.axhline(y=0, color='r', linestyle='--', alpha=0.5)
    plt.xlabel('Epoch')
    plt.ylabel('è®­ç»ƒæŸå¤± - éªŒè¯æŸå¤±')
    plt.title('è¿‡æ‹Ÿåˆç¨‹åº¦ï¼ˆæ­£å€¼å¯èƒ½è¿‡æ‹Ÿåˆï¼‰')
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')
    print(f"ğŸ“ˆ è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: training_history.png")
    plt.show()

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å‹
from mymodels.dinov3_detr import DINOv3DETR


# ==================== 2. åŒˆç‰™åˆ©åŒ¹é…å™¨ ====================
class HungarianMatcher(nn.Module):
    """åŒˆç‰™åˆ©åŒ¹é…å™¨ï¼Œç”¨äºæ‰¾åˆ°æœ€ä½³é¢„æµ‹-ç›®æ ‡åŒ¹é…"""

    def __init__(self, cost_class=1.0, cost_bbox=5.0, cost_giou=2.0):
        super().__init__()
        self.cost_class = cost_class
        self.cost_bbox = cost_bbox
        self.cost_giou = cost_giou

    @torch.no_grad()
    def forward(self, pred_logits, pred_boxes, targets):
        """
        Args:
            pred_logits: [batch_size, num_queries, num_classes+1]
            pred_boxes: [batch_size, num_queries, 4] (cx, cy, w, h)
            targets: list of dict with keys 'boxes', 'labels'
        Returns:
            indices: list of tuples (pred_idx, target_idx) for each batch
        """
        batch_size = pred_logits.shape[0]
        num_queries = pred_logits.shape[1]

        # å­˜å‚¨æ¯å¼ å›¾ç‰‡çš„åŒ¹é…ç»“æœ
        indices = []

        for batch_idx in range(batch_size):
            # è·å–å½“å‰batchçš„ç›®æ ‡
            target_boxes = targets[batch_idx]['boxes']  # [num_targets, 4]
            target_labels = targets[batch_idx]['labels']  # [num_targets]
            num_targets = len(target_boxes)

            # å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œæ‰€æœ‰æŸ¥è¯¢éƒ½åŒ¹é…åˆ°"æ— å¯¹è±¡"
            if num_targets == 0:
                indices.append((torch.tensor([], dtype=torch.int64),
                                torch.tensor([], dtype=torch.int64)))
                continue

            # è®¡ç®—åˆ†ç±»æŸå¤±æˆæœ¬
            pred_logit = pred_logits[batch_idx]  # [num_queries, num_classes+1]

            # è·å–ç›®æ ‡ç±»åˆ«çš„æ¦‚ç‡ï¼ˆè´Ÿå€¼ï¼Œå› ä¸ºåŒˆç‰™åˆ©ç®—æ³•æ‰¾æœ€å°æˆæœ¬ï¼‰
            cost_class = -pred_logit[:, target_labels]  # [num_queries, num_targets]

            # è®¡ç®—L1è¾¹ç•Œæ¡†æŸå¤±æˆæœ¬
            pred_box = pred_boxes[batch_idx]  # [num_queries, 4]
            target_boxes = target_boxes.to(pred_box.device)
            cost_bbox = torch.cdist(pred_box, target_boxes, p=1)  # [num_queries, num_targets]

            # è®¡ç®—GIoUæŸå¤±æˆæœ¬
            cost_giou = -self.generalized_box_iou(
                self.box_cxcywh_to_xyxy(pred_box),
                self.box_cxcywh_to_xyxy(target_boxes)
            )

            # ç»„åˆæˆæœ¬çŸ©é˜µ
            C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou
            C = C.cpu()  # åŒˆç‰™åˆ©ç®—æ³•åœ¨CPUä¸Šè¿è¡Œ

            # æ‰§è¡ŒåŒˆç‰™åˆ©åŒ¹é…
            C = C.reshape(num_queries, -1).detach()

            if num_targets < num_queries:
                # å¦‚æœç›®æ ‡æ•°å°äºæŸ¥è¯¢æ•°ï¼Œå¡«å……è™šæ‹Ÿç›®æ ‡
                C = torch.cat([C, torch.zeros(num_queries, num_queries - num_targets)], dim=1)

            # ä½¿ç”¨scipyçš„çº¿æ€§åˆ†é…ï¼ˆåŒˆç‰™åˆ©ç®—æ³•ï¼‰
            from scipy.optimize import linear_sum_assignment
            indices_i = linear_sum_assignment(C)

            # è½¬æ¢ä¸ºPyTorchå¼ é‡
            indices_i = (torch.as_tensor(indices_i[0], dtype=torch.int64),
                         torch.as_tensor(indices_i[1], dtype=torch.int64))

            # è¿‡æ»¤æ‰è™šæ‹Ÿç›®æ ‡çš„åŒ¹é…
            if num_targets < num_queries:
                mask = indices_i[1] < num_targets
                indices_i = (indices_i[0][mask], indices_i[1][mask])

            indices.append(indices_i)

        return indices

    @staticmethod
    def box_cxcywh_to_xyxy(x):
        """å°†(cx, cy, w, h)è½¬æ¢ä¸º(x1, y1, x2, y2)"""
        x_c, y_c, w, h = x.unbind(-1)
        b = [(x_c - 0.5 * w), (y_c - 0.5 * h),
             (x_c + 0.5 * w), (y_c + 0.5 * h)]
        return torch.stack(b, dim=-1)

    @staticmethod
    def generalized_box_iou(boxes1, boxes2):
        """
        è®¡ç®—å¹¿ä¹‰IoU
        boxes1: [N, 4] (x1, y1, x2, y2)
        boxes2: [M, 4] (x1, y1, x2, y2)
        è¿”å›: [N, M] GIoUå€¼
        """
        # ç¡®ä¿boxes2åœ¨boxes1çš„è®¾å¤‡ä¸Š
        boxes2 = boxes2.to(boxes1.device)

        # è®¡ç®—äº¤é›†é¢ç§¯
        lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # [N, M, 2]
        rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # [N, M, 2]
        wh = (rb - lt).clamp(min=0)  # [N, M, 2]
        inter = wh[:, :, 0] * wh[:, :, 1]  # [N, M]

        # è®¡ç®—å„è‡ªçš„é¢ç§¯
        area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])  # [N]
        area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])  # [M]

        union = area1[:, None] + area2[None, :] - inter

        iou = inter / union

        # è®¡ç®—æœ€å°åŒ…å›´æ¡†
        lt_min = torch.min(boxes1[:, None, :2], boxes2[:, :2])
        rb_max = torch.max(boxes1[:, None, 2:], boxes2[:, 2:])
        wh_min = (rb_max - lt_min).clamp(min=0)
        area_min = wh_min[:, :, 0] * wh_min[:, :, 1]

        # è®¡ç®—GIoU
        giou = iou - (area_min - union) / area_min

        return giou


# ==================== 3. åŒˆç‰™åˆ©æŸå¤±å‡½æ•° ====================
class HungarianLoss(nn.Module):
    """ä½¿ç”¨åŒˆç‰™åˆ©åŒ¹é…çš„DETRæŸå¤±å‡½æ•°"""

    def __init__(self, num_classes, matcher=None):
        super().__init__()
        self.num_classes = num_classes

        # ä½¿ç”¨é»˜è®¤åŒˆç‰™åˆ©åŒ¹é…å™¨
        self.matcher = matcher if matcher is not None else HungarianMatcher()

        # æŸå¤±æƒé‡
        self.weight_class = 1.0
        self.weight_bbox = 5.0
        self.weight_giou = 2.0

        # åŸºç¡€æŸå¤±å‡½æ•°
        self.loss_class = nn.CrossEntropyLoss()
        self.loss_bbox = nn.L1Loss()

    def forward(self, pred_logits, pred_boxes, targets):
        """
        Args:
            pred_logits: [batch, num_queries, num_classes+1]
            pred_boxes: [batch, num_queries, 4]
            targets: list of dict with 'boxes' and 'labels'
        """
        # ç¬¬ä¸€æ­¥ï¼šåŒˆç‰™åˆ©åŒ¹é…æ‰¾åˆ°æœ€ä½³é…å¯¹
        indices = self.matcher(pred_logits, pred_boxes, targets)

        total_loss = 0
        batch_size = pred_logits.shape[0]

        for batch_idx in range(batch_size):
            # è·å–åŒ¹é…ç»“æœ
            idx_pred, idx_target = indices[batch_idx]

            # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ç›®æ ‡ï¼Œè·³è¿‡
            if len(idx_pred) == 0:
                continue

            # æå–åŒ¹é…çš„é¢„æµ‹å’Œç›®æ ‡
            matched_pred_logits = pred_logits[batch_idx, idx_pred]  # [num_matched, num_classes+1]
            matched_pred_boxes = pred_boxes[batch_idx, idx_pred]  # [num_matched, 4]

            target_boxes = targets[batch_idx]['boxes'][idx_target]  # [num_matched, 4]
            target_labels = targets[batch_idx]['labels'][idx_target]  # [num_matched]
            device = pred_logits.device
            target_boxes = target_boxes.to(device)
            target_labels = target_labels.to(device)
            # åˆ†ç±»æŸå¤±
            loss_class = self.loss_class(matched_pred_logits, target_labels)

            # è¾¹ç•Œæ¡†L1æŸå¤±
            loss_bbox = self.loss_bbox(matched_pred_boxes, target_boxes)

            # GIoUæŸå¤±
            loss_giou = 1.0 - self.matcher.generalized_box_iou(
                self.matcher.box_cxcywh_to_xyxy(matched_pred_boxes),
                self.matcher.box_cxcywh_to_xyxy(target_boxes)
            ).diag().mean()

            # ç»„åˆæŸå¤±
            loss = (self.weight_class * loss_class +
                    self.weight_bbox * loss_bbox +
                    self.weight_giou * loss_giou)

            total_loss += loss

        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ç›®æ ‡ï¼Œè®¡ç®—"æ— å¯¹è±¡"çš„åˆ†ç±»æŸå¤±
        if total_loss == 0:
            for batch_idx in range(batch_size):
                if len(targets[batch_idx]['boxes']) == 0:
                    # æ‰€æœ‰é¢„æµ‹éƒ½åº”è¯¥æ˜¯"æ— å¯¹è±¡"
                    cls_target = torch.full((pred_logits.shape[1],),
                                            self.num_classes,
                                            dtype=torch.long,
                                            device=pred_logits.device)
                    loss = self.loss_class(pred_logits[batch_idx], cls_target)
                    total_loss += loss

        return total_loss / max(1, batch_size)

# ==================== 1. è‡ªå®šä¹‰æ•°æ®é›†ï¼ˆå†…è”å®ç°ï¼‰ ====================
class SimpleCOCODataset(Dataset):
    """ç®€åŒ–çš„COCOæ ¼å¼æ•°æ®é›†"""

    def __init__(self, data_root, split='train', image_size=224):
        """
        Args:
            data_root: æ•°æ®æ ¹ç›®å½• (å¦‚: ./datasets/coco)
            split: æ•°æ®é›†åˆ’åˆ† ('train', 'valid', 'test')
            image_size: å›¾åƒå°ºå¯¸
        """
        self.data_root = data_root
        self.split = split
        self.image_size = image_size

        # å›¾åƒç›®å½•
        self.image_dir = os.path.join(data_root, split)

        # æ ‡æ³¨æ–‡ä»¶è·¯å¾„ - ç°åœ¨åœ¨å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶å¤¹ä¸­
        self.annotation_file = os.path.join(self.image_dir, f"{split}.json")
        #æ ‡æ³¨æ–‡ä»¶ç›®å½•

        print(f"å›¾åƒç›®å½•: {self.image_dir}")
        print(f"æ ‡æ³¨æ–‡ä»¶: {self.annotation_file}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.image_dir):
            raise FileNotFoundError(f"å›¾åƒç›®å½•ä¸å­˜åœ¨: {self.image_dir}")
        if not os.path.exists(self.annotation_file):
            raise FileNotFoundError(f"æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {self.annotation_file}")

        # åŠ è½½æ ‡æ³¨
        with open(self.annotation_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # å‡†å¤‡æ•°æ®
        self.images = [] # å›¾åƒè·¯å¾„
        self.targets = [] # æ ‡æ³¨ä¿¡æ¯

        # å»ºç«‹å›¾åƒæ˜ å°„
        image_dict = {img['id']: img for img in data['images']}
        # å»ºç«‹æ ‡æ³¨æ˜ å°„ imagesä¸­å­˜æ”¾çš„å›¾ç‰‡çš„idå’Œå›¾ç‰‡çš„ä¿¡æ¯ç°åœ¨å°±å¯ä»¥ç”¨idæ‰¾åˆ°ä¿¡æ¯
        #åˆ›å»ºå›¾åƒ# ç»“æœï¼š{0: ç¬¬ä¸€å¼ å›¾ç‰‡ä¿¡æ¯, 1: ç¬¬äºŒå¼ å›¾ç‰‡ä¿¡æ¯, 2: ç¬¬ä¸‰å¼ å›¾ç‰‡ä¿¡æ¯}
        ann_dict = {}

        # ç»„ç»‡æ ‡æ³¨
        for ann in data['annotations']:
            img_id = ann['image_id']
            if img_id not in ann_dict:
                ann_dict[img_id] = []
            ann_dict[img_id].append(ann)
        #annotationsä¸­å­˜æ”¾è¿™æ‰€ä»¥å›¾ç‰‡çš„æ‰€ä»¥æ ‡æ³¨çš„ç‚¹åæ ‡ï¼Œé€šè¿‡éå†ï¼Œæ¥åˆ†ç±»ï¼Œann_dictå°±æ˜¯å­˜å‚¨å›¾ç‰‡idï¼Œ
        # å¦‚æœè¿˜æ²¡å­˜å‚¨æŸä¸€å¼ çš„å›¾ç‰‡å°±å°†ä¸‹æ ‡ä¸ºè¯¥idçš„æ•°ç»„åˆ›å»ºä¸€ä¸ªåˆ—è¡¨
        #ç”¨æ¥å°†è¯¥å›¾ç‰‡çš„æ‰€ä»¥ç‚¹åæ ‡åˆ†ç±»
        # ç»“æœï¼š{0: [æ ‡æ³¨1-7], 1: [æ ‡æ³¨8-11], 2: [æ ‡æ³¨12-17]}
        # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
        images_found = 0
        for img_id, img_info in image_dict.items():
            # å›¾åƒæ–‡ä»¶å
            filename = img_info['file_name']

            # å›¾åƒè·¯å¾„ - ç°åœ¨åœ¨å¯¹åº”çš„splitç›®å½•ä¸­
            img_path = os.path.join(self.image_dir, filename)

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(img_path):
                print(f"âš ï¸ è­¦å‘Š: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
                # å°è¯•ä½¿ç”¨ç»å¯¹è·¯å¾„
                img_path = os.path.abspath(img_path)
                if not os.path.exists(img_path):
                    print(f"  ç»å¯¹è·¯å¾„ä¹Ÿä¸å­˜åœ¨: {img_path}")
                    continue

            images_found += 1

            # è·å–è¯¥å›¾åƒçš„æ‰€æœ‰æ ‡æ³¨
            anns = ann_dict.get(img_id, [])
            boxes = [] #è¾¹ç•Œæ¡†
            labels = []#ç±»åˆ«

            for ann in anns:
                # è¾¹ç•Œæ¡† [x, y, w, h] å½’ä¸€åŒ–
                bbox = ann['bbox']
                x, y, w, h = bbox

                # å½’ä¸€åŒ–åˆ°0-1
                x = x / img_info['width']
                y = y / img_info['height']
                w = w / img_info['width'] #å®½åº¦ç™¾åˆ†æ¯”ï¼ŒåŠ ä¸Šxç™¾åˆ†æ¯”å°±ç­‰äºå³è¾¹xçš„ç™¾åˆ†æ¯”
                h = h / img_info['height']

                boxes.append([x, y, w, h])
                labels.append(ann['category_id'] - 1)  # 0-based
                #ç±»åˆ«æ ‡ç­¾idï¼Œç»“æ„æ˜¯ä»1å¼€å§‹ï¼Œæˆ‘ä»¬æ”¹ä¸ºä»é›¶å¼€å§‹

            self.images.append(img_path)
            self.targets.append({
                'boxes': torch.tensor(boxes, dtype=torch.float32) if boxes else# torch.Size([3, 4])
                torch.zeros((0, 4), dtype=torch.float32),#å›¾ç‰‡æ²¡æœ‰æ ‡æ³¨æ—¶
                # tensor([[0.2000, 0.3000, 0.1000, 0.1500],
                #         [0.5000, 0.4000, 0.2000, 0.1000],
                #         [0.7000, 0.6000, 0.1500, 0.2000]])
                'labels': torch.tensor(labels, dtype=torch.long) if labels else# torch.Size([3])
                # tensor([2, 0, 1])
                torch.zeros((0,), dtype=torch.long)
            })

        print(f"æ•°æ®é›†åŠ è½½å®Œæˆ: {len(self.images)} å¼ å›¾ç‰‡")
        print(f"  æ ‡æ³¨æ–‡ä»¶ä¸­å›¾åƒ: {len(image_dict)} å¼ ")
        print(f"  å®é™…æ‰¾åˆ°å›¾åƒ: {images_found} å¼ ")

        if self.images:
            print(f"ç¤ºä¾‹å›¾åƒè·¯å¾„: {self.images[0]}")
            print(f"ç¤ºä¾‹ç›®æ ‡: {len(self.targets[0]['boxes'])} ä¸ªè¾¹ç•Œæ¡†")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):#é€šè¿‡å¯¹è±¡[ï¼Ÿ]æ¥å°†è¯¥å›¾ç‰‡è½¬æ¢æˆæ¨¡å‹èƒ½çœ‹åˆ°çš„æ•°æ®ï¼Œä»è€Œç»™åˆ°æ¨¡å‹
        # åŠ è½½å›¾åƒ
        try:
            img = Image.open(self.images[idx]).convert('RGB')# ğŸ”¥ è¿™é‡Œè½¬æ¢æˆRGBä¸‰é€šé“
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½å›¾åƒ {self.images[idx]}: {e}")
            # è¿”å›ä¸€ä¸ªç™½è‰²å ä½å›¾åƒ
            img = Image.new('RGB', (self.image_size, self.image_size), color='white')

        img = img.resize((self.image_size, self.image_size))

        # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–
        img_tensor = torch.from_numpy(np.array(img)).permute(2, 0, 1).float() / 255.0
        # ğŸ”¥ è¿™é‡Œï¼šarray(img) â†’ [H, W, 3] ä¸‰é€šé“
        # ğŸ”¥ permute(2, 0, 1) â†’ [3, H, W] é€šé“åœ¨å‰
        # img_tensor = torch.tensor([
        #     # çº¢è‰²é€šé“ (R)
        #     [[0.9, 0.2, 0.5],  # ç¬¬1è¡Œï¼š3ä¸ªåƒç´ çš„çº¢è‰²å€¼
        #      [0.3, 0.8, 0.1],  # ç¬¬2è¡Œ
        #      [0.7, 0.4, 0.6]],  # ç¬¬3è¡Œ
        #
        #     # ç»¿è‰²é€šé“ (G)
        #     [[0.1, 0.8, 0.3],
        #      [0.6, 0.2, 0.9],
        #      [0.4, 0.7, 0.5]],
        #
        #     # è“è‰²é€šé“ (B)
        #     [[0.5, 0.3, 0.9],
        #      [0.2, 0.7, 0.4],
        #      [0.8, 0.1, 0.6]]
        # ])  # å½¢çŠ¶ï¼š[3, 3, 3] = [é€šé“, é«˜åº¦, å®½åº¦]
        return img_tensor, self.targets[idx]


def collate_fn(batch):   #å°†å›¾ç‰‡å˜ä¸ºå¼ é‡ç„¶åå †å 
    """è‡ªå®šä¹‰æ‰¹æ¬¡å¤„ç†"""
    images = []
    targets = []

    for img, target in batch:
        images.append(img)  #å­˜æ”¾å›¾ç‰‡ ç°åœ¨æ˜¯é“¾è¡¨å½¢å¼å­˜æ”¾
        targets.append(target) #å­˜æ”¾æ ‡ç­¾

    images = torch.stack(images, dim=0) #å°†å›¾åƒçš„åƒç´ å€¼è¿ç»­å­˜å‚¨èµ·æ¥ï¼Œå †å æˆä¸€ä¸ªå¼ é‡ï¼ˆæ¨¡å‹ä¸€æ¬¡è®­ç»ƒä¸€ä¸ªå¼ é‡ï¼‰ï¼Œdim=0åœ¨é›¶ï¼ˆæœ€å‰é¢ï¼‰ç»´åº¦æ·»åŠ ç»´åº¦
    return images, targets


# ==================== 2. æ—§çš„æŸå¤±å‡½æ•°ï¼ˆå†…è”å®ç°ï¼‰ ====================
class SimpleDetrLoss(nn.Module):
    """ç®€åŒ–çš„DETRæŸå¤±å‡½æ•°"""

    def __init__(self, num_classes):
        super().__init__()
        self.num_classes = num_classes#éœ€è¦æ£€æµ‹ç§ç±»
        # åˆ†ç±»æŸå¤±
        self.cls_loss = nn.CrossEntropyLoss()#äº¤å‰ç†µæŸå¤±å‡½æ•°
        # è¾¹ç•Œæ¡†æŸå¤±
        self.bbox_loss = nn.L1Loss()#å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°
        #ç»™è¿™ä¸ªå‡½æ•°å®šä¹‰ä»–æŸå¤±æ‰€ä»¥çš„è¿ç®—å‡½æ•°

    def forward(self, pred_logits, pred_boxes, targets):
        """
        pred_logits: [batch, num_queries, num_classes+1],è¯†åˆ«å‡ºçš„ç§ç±»ç™¾åˆ†æ¯”
        pred_boxes: [batch, num_queries, 4] è¯†åˆ«å‡ºçš„åæ ‡
        targets: list of dict with 'boxes' and 'labels'  ç­”æ¡ˆ
        """
        batch_size = pred_logits.shape[0]#æ ·æœ¬æ•°é‡
        total_loss = 0

        for i in range(batch_size):
            # è·å–ç›®æ ‡
            target_boxes = targets[i]['boxes']  # [num_objects, 4]
            target_labels = targets[i]['labels']  # [num_objects]

            # å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œåªè®¡ç®—"æ— å¯¹è±¡"çš„åˆ†ç±»æŸå¤±
            if len(target_boxes) == 0:
                # æ‰€æœ‰é¢„æµ‹éƒ½åº”è¯¥æ˜¯"æ— å¯¹è±¡"
                cls_target = torch.full((pred_logits.shape[1],),
                                        self.num_classes,  # "æ— å¯¹è±¡"ç±»åˆ« è¿™é‡Œçš„num_classesä¸æ˜¯ä»£è¡¨æœ‰å¤šå°‘ç±»ï¼Œè€Œæ˜¯ä»£è¡¨ä»–æ˜¯ç¬¬å‡ ç±»ï¼Œåˆšå¥½æ˜¯æ— ç±»å‹
                                        dtype=torch.long,
                                        device=pred_logits.device)#ä¸é¢„æµ‹å¼ é‡åŒä¸€è®¾å¤‡
                loss = self.cls_loss(pred_logits[i], cls_target)#å°†ç¬¬nå¼ å›¾ç‰‡ä¸­çš„100ä¸ªé¢„æµ‹ç›®æ ‡çš„é¢„æµ‹ç§ç±»ï¼Œå’Œç­”é¢˜å¡
                total_loss += loss
                continue

            # ç®€åŒ–çš„åŒ¹é…ï¼šæ¯ä¸ªç›®æ ‡åˆ†é…ç»™ä¸€ä¸ªæŸ¥è¯¢
            num_objects = min(len(target_boxes), pred_logits.shape[1]) #ç­”æ¡ˆä¸­çš„ç›®æ ‡æ•°å’ŒæŸ¥è¯¢åˆ°çš„ç›®æ ‡æ•°çš„æœ€å°å€¼

            # åˆ†ç±»æŸå¤±
            cls_target = torch.full((pred_logits.shape[1],),
                                    self.num_classes,  # é»˜è®¤"æ— å¯¹è±¡"
                                    dtype=torch.long,
                                    device=pred_logits.device)
            cls_target[:num_objects] = target_labels[:num_objects] #å°†ç­”æ¡ˆä¸­çš„ç›®æ ‡æ•°ï¼Œå’ŒæŸ¥è¯¢åˆ°çš„ç›®æ ‡æ•°çš„æœ€å°å€¼ï¼Œä½œä¸ºç­”æ¡ˆ(éå¸¸ä½çº§)
            loss_cls = self.cls_loss(pred_logits[i], cls_target)
        #ï¼Œè€å¸ˆå…ˆå°†åšä¸€ä»½å…¨ç©ºçš„ç­”æ¡ˆï¼Œè¡¨æ˜å…¨éƒ¨æ²¡æœ‰ç­”æ¡ˆï¼Œç„¶ååœ¨æœ‰ç­”æ¡ˆçš„ä¸‹æ ‡æ•°ç»„ä¸­å¡«å…¥çœŸç¡®ç­”æ¡ˆï¼Œè¿™æ ·åˆ°æ—¶å€™æ£€æµ‹æ—¶ï¼Œç©ºçš„å°±è¡¨æ˜ä¸€å®šé”™è¯¯ï¼Œä¸ç©ºçš„è¯ï¼Œå†è¿›è¡Œæ¯”å¯¹
            # è¾¹ç•Œæ¡†æŸå¤±
            loss_bbox = self.bbox_loss(pred_boxes[i, :num_objects],target_boxes[:num_objects])#ç¬¬iå¼ å›¾çš„æ‰€æœ‰æ£€æµ‹ç›®æ ‡å’Œæ ‡å‡†ç­”æ¡ˆ

            total_loss += loss_cls + 5.0 * loss_bbox  # ç»™bboxæŸå¤±æ›´é«˜æƒé‡ï¼ˆè¾¹æ¡†æŸå¤±çœ‹çš„æ›´é‡ï¼‰

        return total_loss / batch_size


# ==================== 3. è®­ç»ƒå‡½æ•° ====================
def train_detr_head():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # ========== æ•°æ®é›†è·¯å¾„ ==========
    data_root = "./datasets/coco"
    train_split = "train"
    val_split = "valid"
    # ===============================

    # åˆ›å»ºæ•°æ®é›†
    print("åŠ è½½æ•°æ®é›†...")
    try:
        train_dataset = SimpleCOCODataset(data_root, split=train_split, image_size=224)
        print(f"âœ… è®­ç»ƒé›†åŠ è½½æˆåŠŸ: {len(train_dataset)} å¼ å›¾ç‰‡")
    except Exception as e:
        print(f"âŒ è®­ç»ƒé›†åŠ è½½å¤±è´¥: {e}")
        return

    try:
        val_dataset = SimpleCOCODataset(data_root, split=val_split, image_size=224)
        print(f"âœ… éªŒè¯é›†åŠ è½½æˆåŠŸ: {len(val_dataset)} å¼ å›¾ç‰‡")
    except Exception as e:
        print(f"âš ï¸ éªŒè¯é›†åŠ è½½å¤±è´¥: {e}")
        print("âš ï¸ å°†ä½¿ç”¨è®­ç»ƒé›†çš„ä¸€éƒ¨åˆ†ä½œä¸ºéªŒè¯é›†")

    # åˆ›å»ºDataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=8,  # ğŸ”¥ æ³¨æ„ï¼šè¿™é‡Œè¿˜æ˜¯2ï¼Œä½†é€šè¿‡æ¢¯åº¦ç´¯ç§¯ç­‰æ•ˆæ”¾å¤§
        shuffle=True,
        num_workers=0,
        collate_fn=collate_fn
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=8,
        shuffle=False,
        num_workers=0,
        collate_fn=collate_fn
    )

    print(f"è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾ç‰‡")
    print(f"éªŒè¯é›†: {len(val_dataset)} å¼ å›¾ç‰‡")
    print(f"è®­ç»ƒæ‰¹æ¬¡å¤§å°: {train_loader.batch_size}")
    print(f"è®­ç»ƒæ­¥æ•°/epoch: {len(train_loader)}")

    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    try:
        model = DINOv3DETR(num_classes=10).to(device)
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return

    # åˆ›å»ºæŸå¤±å‡½æ•°
    criterion = HungarianLoss(num_classes=10).to(device)
    print("âœ… ä½¿ç”¨åŒˆç‰™åˆ©åŒ¹é…æŸå¤±å‡½æ•°")

    # ========== ğŸ”¥ ä¼˜åŒ–1: æ¢¯åº¦ç´¯ç§¯è®¾ç½® ==========
    accumulation_steps = 2  # ç´¯ç§¯8ä¸ªbatchï¼Œç›¸å½“äºbatch_size=16
    effective_batch_size = train_loader.batch_size * accumulation_steps

    # æ ¹æ®æ¢¯åº¦ç´¯ç§¯è°ƒæ•´å­¦ä¹ ç‡ï¼ˆç»éªŒå…¬å¼ï¼‰
    base_lr = 1e-4
    adjusted_lr = base_lr * (effective_batch_size / train_loader.batch_size) ** 0.5

    print(f"\nğŸ¯ æ¢¯åº¦ç´¯ç§¯é…ç½®:")
    print(f"  å®é™…batch_size: {train_loader.batch_size}")
    print(f"  ç´¯ç§¯æ­¥æ•°: {accumulation_steps}")
    print(f"  ç­‰æ•ˆbatch_size: {effective_batch_size}")
    print(f"  è°ƒæ•´åå­¦ä¹ ç‡: {adjusted_lr:.2e} (åŸ: {base_lr:.2e})")
    # ==========================================

    # ========== ğŸ”¥ ä¼˜åŒ–2: å­¦ä¹ ç‡é¢„çƒ­å‚æ•° ==========
    warmup_epochs = 3  # é¢„çƒ­3ä¸ªepoch
    lr_schedule_method = 'cosine'  # ä½™å¼¦è¡°å‡ï¼ˆæ¯”é˜¶æ¢¯è¡°å‡æ›´å¹³æ»‘ï¼‰

    print(f"\nğŸ¯ å­¦ä¹ ç‡é¢„çƒ­é…ç½®:")
    print(f"  é¢„çƒ­epochæ•°: {warmup_epochs}")
    print(f"  è¡°å‡ç­–ç•¥: {lr_schedule_method}")
    # ============================================

    # ========== ğŸ”¥ ä¼˜åŒ–3: æ—©åœç­–ç•¥å‚æ•° ==========
    patience = 5  # å®¹å¿è¿ç»­5ä¸ªepochéªŒè¯æŸå¤±ä¸ä¸‹é™
    best_val_loss = float('inf')  # æœ€ä½³éªŒè¯æŸå¤±
    patience_counter = 0  # å½“å‰è¿ç»­ä¸ä¸‹é™æ¬¡æ•°
    best_model_path = 'best_detr_model.pth'  # æœ€ä½³æ¨¡å‹ä¿å­˜è·¯å¾„

    # è®°å½•è®­ç»ƒå†å²
    train_history = {
        'epoch': [],
        'train_loss': [],
        'val_loss': [],
        'lr': []
    }

    print(f"\nğŸ¯ æ—©åœç­–ç•¥é…ç½®:")
    print(f"  å®¹å¿è¿ç»­ä¸ä¸‹é™epochæ•°: {patience}")
    print(f"  æœ€ä½³æ¨¡å‹ä¿å­˜è·¯å¾„: {best_model_path}")
    # ===========================================

    # åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨è°ƒæ•´åçš„å­¦ä¹ ç‡ï¼‰
    optimizer = optim.AdamW(
        model.detr_head.parameters(),
        lr=adjusted_lr,  # ğŸ”¥ ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯è°ƒæ•´åçš„å­¦ä¹ ç‡
        weight_decay=1e-4
    )

    # ğŸ”¥ æ³¨æ„ï¼šåˆ é™¤åŸæ¥çš„StepLRè°ƒåº¦å™¨ï¼Œæ”¹ä¸ºæ‰‹åŠ¨æ§åˆ¶
    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)

    # è®­ç»ƒå¾ªç¯
    num_epochs = 100
    print(f"\nå¼€å§‹è®­ç»ƒDETRæ£€æµ‹å¤´ ({num_epochs}ä¸ªepoch)...")
    print("=" * 60)

    for epoch in range(num_epochs):
        # ğŸ”¥ ä¼˜åŒ–2: åœ¨æ¯ä¸ªepochå¼€å§‹è°ƒæ•´å­¦ä¹ ç‡ï¼ˆé¢„çƒ­+è¡°å‡ï¼‰
        current_lr = adjust_learning_rate(
            optimizer, epoch, warmup_epochs,
            base_lr=adjusted_lr,  # ä½¿ç”¨è°ƒæ•´åçš„åŸºç¡€å­¦ä¹ ç‡
            num_epochs=num_epochs,
            method=lr_schedule_method
        )

        # è®­ç»ƒæ¨¡å¼
        model.train()
        train_loss = 0
        train_items = 0

        # ğŸ”¥ ä¼˜åŒ–1: æ¢¯åº¦ç´¯ç§¯è®¡æ•°å™¨
        accumulation_counter = 0

        # è®­ç»ƒä¸€ä¸ªepoch
        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}')

        for batch_idx, (images, targets) in enumerate(progress_bar):
            images = images.to(device)

            # å‰å‘ä¼ æ’­
            pred_logits, pred_boxes = model(images)

            # è®¡ç®—æŸå¤±
            loss = criterion(pred_logits, pred_boxes, targets)

            # ğŸ”¥ ä¼˜åŒ–1: æ¢¯åº¦ç´¯ç§¯ - ç¼©æ”¾æŸå¤±
            loss = loss / accumulation_steps

            # ğŸ”¥ ä¼˜åŒ–1: æ¢¯åº¦ç´¯ç§¯ - åå‘ä¼ æ’­ï¼ˆç´¯ç§¯æ¢¯åº¦ï¼‰
            loss.backward()

            # ğŸ”¥ ä¼˜åŒ–1: æ¢¯åº¦ç´¯ç§¯ - è®¡æ•°å™¨+1
            accumulation_counter += 1

            # ğŸ”¥ ä¼˜åŒ–1: æ¢¯åº¦ç´¯ç§¯ - åˆ¤æ–­æ˜¯å¦è¾¾åˆ°ç´¯ç§¯æ­¥æ•°
            if accumulation_counter % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

                # æ›´æ–°æƒé‡
                optimizer.step()

                # æ¸…ç©ºæ¢¯åº¦
                optimizer.zero_grad()

                # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤ºï¼ˆæ³¨æ„è¿˜åŸçœŸå®æŸå¤±å€¼ï¼‰
                real_loss = loss.item() * accumulation_steps
                progress_bar.set_postfix({
                    'loss': f'{real_loss:.4f}',
                    'avg_loss': f'{train_loss / (batch_idx + 1):.4f}',
                    'lr': f'{current_lr:.2e}',  # ğŸ”¥ æ˜¾ç¤ºå½“å‰å­¦ä¹ ç‡
                    'step': f'{(batch_idx + 1) // accumulation_steps}/{(len(train_loader) + accumulation_steps - 1) // accumulation_steps}'
                })

            # ğŸ”¥ è®°å½•æŸå¤±ï¼ˆæ³¨æ„ï¼šä¹˜å›accumulation_stepså¾—åˆ°çœŸå®æŸå¤±ï¼‰
            real_loss = loss.item() * accumulation_steps
            train_loss += real_loss
            train_items += images.shape[0]

        # ğŸ”¥ ä¼˜åŒ–1: ç¡®ä¿æœ€åä¸€æ‰¹ä¹Ÿæ›´æ–°ï¼ˆå¦‚æœè¿˜æœ‰æœªæ›´æ–°çš„æ¢¯åº¦ï¼‰
        if accumulation_counter % accumulation_steps != 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            optimizer.zero_grad()

        # éªŒè¯
        model.eval()
        val_loss = 0
        val_items = 0

        with torch.no_grad():
            for images, targets in val_loader:
                images = images.to(device)
                pred_logits, pred_boxes = model(images)
                loss = criterion(pred_logits, pred_boxes, targets)
                val_loss += loss.item()
                val_items += images.shape[0]

        # ğŸ”¥ æ³¨æ„ï¼šåˆ é™¤åŸæ¥çš„scheduler.step()è°ƒç”¨
        # scheduler.step()

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_train_loss = train_loss / len(train_loader) if len(train_loader) > 0 else 0
        avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0

        # ğŸ”¥ ä¼˜åŒ–3: è®°å½•è®­ç»ƒå†å²
        train_history['epoch'].append(epoch + 1)
        train_history['train_loss'].append(avg_train_loss)
        train_history['val_loss'].append(avg_val_loss)
        train_history['lr'].append(current_lr)

        # ğŸ”¥ ä¼˜åŒ–3: æ—©åœåˆ¤æ–­
        if avg_val_loss < best_val_loss:
            # æœ‰æ”¹å–„ï¼šä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œé‡ç½®è®¡æ•°å™¨
            improvement = best_val_loss - avg_val_loss
            best_val_loss = avg_val_loss
            patience_counter = 0

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': avg_val_loss,
                'train_loss': avg_train_loss,
                'learning_rate': current_lr,
            }, best_model_path)

            print(f"\nEpoch {epoch + 1}/{num_epochs} å®Œæˆ:")
            print(f"  ğŸ† æœ€ä½³æ¨¡å‹æ›´æ–°ï¼éªŒè¯æŸå¤±: {avg_val_loss:.6f} (æå‡: {improvement:.6f})")

        else:
            # æ²¡æœ‰æ”¹å–„ï¼šè®¡æ•°å™¨+1
            patience_counter += 1

            print(f"\nEpoch {epoch + 1}/{num_epochs} å®Œæˆ:")
            print(f"  âš ï¸ éªŒè¯æŸå¤±æœªæ”¹å–„ ({patience_counter}/{patience})")

        print(f"  è®­ç»ƒæŸå¤±: {avg_train_loss:.6f}")
        print(f"  éªŒè¯æŸå¤±: {avg_val_loss:.6f}")
        print(f"  å­¦ä¹ ç‡: {current_lr:.2e}")

        # ğŸ”¥ ä¼˜åŒ–3: æ£€æŸ¥æ˜¯å¦éœ€è¦æ—©åœ
        if patience_counter >= patience:
            print(f"\nğŸš« æ—©åœè§¦å‘ï¼è¿ç»­{patience}ä¸ªepochéªŒè¯æŸå¤±æœªæ”¹å–„")
            print(f"   æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
            break  # è·³å‡ºè®­ç»ƒå¾ªç¯

        # ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆæ¯2ä¸ªepochæˆ–æœ€åï¼‰
        if (epoch + 1) % 10 == 0 or epoch == num_epochs - 1:
            save_path = f'detr_head_epoch_{epoch + 1}.pth'
            torch.save(model.detr_head.state_dict(), save_path)
            print(f"  ğŸ’¾ å½“å‰æ¨¡å‹ä¿å­˜åˆ°: {save_path}")

           # checkpoint_path = f'checkpoint_epoch_{epoch + 1}.pth'
           #  torch.save({
           #      'epoch': epoch + 1,
           #      'model_state_dict': model.state_dict(),
           #      'optimizer_state_dict': optimizer.state_dict(),
           #      'train_loss': avg_train_loss,
           #      'val_loss': avg_val_loss,
           #      'learning_rate': current_lr,
           #  }, checkpoint_path)
           # print(f"  ğŸ“¦ æ£€æŸ¥ç‚¹ä¿å­˜åˆ°: {checkpoint_path}")

    print("\n" + "=" * 60)

    # ğŸ”¥ ä¼˜åŒ–3: è®­ç»ƒç»“æŸååŠ è½½æœ€ä½³æ¨¡å‹
    if os.path.exists(best_model_path):
        print(f"ğŸ”„ åŠ è½½æœ€ä½³æ¨¡å‹: {best_model_path}")
        checkpoint = torch.load(best_model_path)
        model.load_state_dict(checkpoint['model_state_dict'])

        print(f"   æœ€ä½³éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
        print(f"   å¯¹åº”è®­ç»ƒæŸå¤±: {checkpoint['train_loss']:.6f}")
        print(f"   å¯¹åº”epoch: {checkpoint['epoch']}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼Œä½¿ç”¨æœ€åepochçš„æ¨¡å‹")

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹ï¼ˆç°åœ¨ä¿å­˜çš„æ˜¯æœ€ä½³æ¨¡å‹ï¼‰
    final_path = 'your_model.pth'
    torch.save(model.detr_head.state_dict(), final_path)

    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: {final_path}")

    # æ˜¾ç¤ºè®­ç»ƒæ€»ç»“
    print("\nğŸ“Š è®­ç»ƒæ€»ç»“:")
    print(f"  æ€»epochæ•°: {min(epoch + 1, num_epochs)}")  # è€ƒè™‘æ—©åœå¯èƒ½æå‰ç»“æŸ
    print(f"  è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"  éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    print(f"  æ‰¹æ¬¡å¤§å°: {train_loader.batch_size}")
    print(f"  æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {accumulation_steps}")
    print(f"  ç­‰æ•ˆbatch_size: {effective_batch_size}")
    print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
    print("=" * 60)

    # ğŸ”¥ å¯é€‰ï¼šç»˜åˆ¶è®­ç»ƒå†å²
    try:
        plot_training_history(train_history)
    except Exception as e:
        print(f"âš ï¸ è®­ç»ƒå†å²ç»˜å›¾å¤±è´¥: {e}")


# ==================== 4. ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == '__main__':
    #è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
    torch.manual_seed(42)
    np.random.seed(42)

    # å¿½ç•¥è­¦å‘Š
    warnings.filterwarnings('ignore')

    # è¿è¡Œè®­ç»ƒ
    train_detr_head()